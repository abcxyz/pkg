# Copyright 2023 The Authors (see AUTHORS file)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: 'Deploy Dataflow Pipeline'
description: 'Deploys a Dataflow pipeline to GCP'

inputs:
  wif_provider:
    description: 'The WIF provider to use when authenticating with GCP'
    required: true
  wif_service_account:
    description: 'The WIF service account to use when authenticating with GCP'
    required: true
  image:
    description: 'The container image that contains the pipeline to execute.'
    required: true
  template_metadata_file:
    description: 'The local file containing the template metadata defining the pipeline.'
    required: true
  template_file_name:
    description: 'The name of the compiled template file that will be stored in GCS.'
    required: true
  project:
    description: 'The GCP Project to use.'
    required: true
  region:
    description: 'The GCP region to use.'
    required: true
  bucket_name:
    description: 'The gcs bucket to store the template file.'
    required: true
  network_name:
    description: 'The name of GCP network to use.'
    required: true
  subnet_name:
    description: 'Then name of the subnet to use.'
    required: false
  pipeline_name:
    description: 'The name of the pipeline.'
    required: true
  pipeline_sdk:
    description: 'SDK language of the pipeline. Must be one of: JAVA, PYTHON, GO.'
    required: true
  pipeline_type:
    description: 'The type of pipeline. Must be one of: BATCH, STREAMING.'
    required: true
  pipeline_schedule:
    description: 'The cron formatted schedule for the pipeline.'
    required: true
  pipeline_experiments:
    description: 'Experiment flags that should be enabled for the pipeline. Default: use_prime'
    default: 'use_prime'
    required: false
  pipeline_parameters:
    description: 'The command line parameters for the pipeline.'
    required: false


runs:
  using: 'composite'
  steps:
    - name: 'Emit deprecation warning'
      shell: 'bash'
      run: |-
        echo "::warning::This action has moved to its own repo and will be removed in a future release. Please upgrade to abcxyz/actions/.github/actions/deploy-dataflow-pipeline instead."

    - name: 'run abcxyz/actions'
      uses: 'abcxyz/actions/.github/actions/deploy-dataflow-pipeline@main' # ratchet:exclude
      with:
        wif_provider: '${{ inputs.wif_provider }}'
        wif_service_account: '${{ inputs.wif_service_account }}'
        image: '${{ inputs.image }}'
        template_metadata_file: '${{ inputs.template_metadata_file }}'
        template_file_name: '${{ inputs.template_file_name }}'
        project: '${{ inputs.project }}'
        region: '${{ inputs.region }}'
        bucket_name: '${{ inputs.bucket_name }}'
        network_name: '${{ inputs.network_name }}'
        subnet_name: '${{ inputs.subnet_name }}'
        pipeline_name: '${{ inputs.pipeline_name }}'
        pipeline_sdk: '${{ inputs.pipeline_sdk }}'
        pipeline_type: '${{ inputs.pipeline_type }}'
        pipeline_schedule: '${{ inputs.pipeline_schedule }}'
        pipeline_experiments: '${{ inputs.pipeline_experiments }}'
        pipeline_parameters: '${{ inputs.pipeline_parameters }}'
